---
title             : "Peekbank: Exploring children's word recognition through an open, large-scale repository for developmental eye-tracking data"
shorttitle        : "Peekbank repository for developmental eye-tracking data"

author: 
  - name          : "Peekbank team"
    affiliation   : "2"
    corresponding : yes    # Define only one corresponding author
    address       : "Postal address"
    email         : "my@email.com"
    role:         # Contributorship roles (e.g., CRediT, https://casrai.org/credit/)
      - Conceptualization
      - Writing - Original Draft Preparation
      - Writing - Review & Editing
  - name          : "Martin Zettersten"
    affiliation   : "1"
  - name          : "Claire Bergey"
    affiliation   : "2"
  - name          : "Naiti S. Bhatt"
    affiliation   : "3"
  - name          : "Veronica Boyce"
    affiliation   : "4"
  - name          : "Mika Braginsky"
    affiliation   : "5"
  - name          : "Alexandra Carstensen"
    affiliation   : "4"
  - name          : "Benny deMayo"
    affiliation   : "1"
  - name          : "George Kachergis"
    affiliation   : "4"
  - name          : "Molly Lewis"
    affiliation   : "6"
  - name          : "Bria Long"
    affiliation   : "4"
  - name          : "Kyle MacDonald"
    affiliation   : "7"
  - name          : "Jessica Mankewitz"
    affiliation   : "4"
  - name          : "Stephan Meylan"
    affiliation   : "5,8"
  - name          : "Annissa N. Saleh"
    affiliation   : "9"
  - name          : "Rose M. Schneider"
    affiliation   : "10"
  - name          : "Angeline Sin Mei Tsui"
    affiliation   : "4"
  - name          : "Sarp Uner"
    affiliation   : "8"
  - name          : "Tian Linger Xu"
    affiliation   : "11"
  - name          : "Daniel Yurovsky"
    affiliation   : "6"
  - name          : "Michael C. Frank"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Dept. of Psychology, Princeton University"
  - id            : "2"
    institution   : "Dept. of Psychology, University of Chicago"
  - id            : "3"
    institution   : "Scripps College"
  - id            : "4"
    institution   : "Dept. of Psychology, Stanford University"
  - id            : "5"
    institution   : "Dept. of Brain and Cognitive Sciences, MIT"
  - id            : "6"
    institution   : "Dept. of Psychology, Carnegie Mellon University"
  - id            : "7"
    institution   : "Core Technology, McD Tech Labs"
  - id            : "8"
    institution   : "Dept. of Psychology and Neuroscience, Duke University"
  - id            : "9"
    institution   : "Dept. of Psychology, UT Austin"
  - id            : "10"
    institution   : "Dept. of Psychology, UC San Diego"
  - id            : "11"
    institution   : "Dept. of Psychological and Brain Sciences, Indiana University"

authornote: |
  Add complete departmental affiliations for each author here. Each new line herein must be indented, like this line.

  Enter author note here.

abstract: |
  The ability to rapidly recognize words and link them to referents in context is central to children’s early language development. 
  This ability, often called word recognition in the developmental literature, is typically studied in the looking-while-listening paradigm, which measures infants’ fixation on a target object (vs. a distractor) after hearing a target label. 
  We present a large-scale, open database of infant and toddler eye-tracking data from looking-while-listening tasks. 
  The goal of this effort is to address theoretical and methodological challenges in measuring vocabulary development. 
  [tools; processing; analysis/ usage examples]
  
  <!-- https://tinyurl.com/ybremelq -->
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["peekbank.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : yes
mask              : no
draft             : no
figsintext        : yes
documentclass     : "apa6"
classoption       : "man"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
library("papaja")
library("here")
library("png")
library("tidyverse")
library("peekbankr")
library("xtable")
library(extrafont)
#extrafont::font_import()
extrafont::loadfonts()
r_refs("peekbank.bib")
```

```{r analysis-preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed,warning=F,
                      message=F)
```

# Introduction

Across their first years of life, children learn words in their native tongues at a rapid pace (Frank, Braginsky, Yurovsky, & Marchman, 2021).
[notes about the size/ pace]
A key part of the word learning process is children’s emerging ability to rapidly process words and link them to relevant meanings – often referred to as word recognition. 
Measuring early word recognition offers insight into children's early word representations and the processes supporting early language comprehension (Bergelson, 2020).
Word recognition skills are also thought to build a foundation for children’s subsequent language development. 
Past research has found that early word recognition efficiency is predictive of later linguistic and general cognitive outcomes (Bleses, Makransky, Dale, Højen, & Ari, 2016; Marchman et al., 2018).
While word recognition is a central part of children's language development, mapping the trajectory of word recognition skills has remained elusive. 
Studies investigating children's word recognition are typically limited in scope to experiments in individual labs involving small samples tested on a limited set of items.
This limitation in scale makes it difficult to understand developmental changes in children's word knowledge at a broad scale.
Peekbank provides an openly accessible database of eye-tracking data of children's word recognition, with the primary goal of facilitating the study of developmental changes in children's word knowledge and recognition speed.

## The “Looking-While-Listening” Paradigm
Word recognition is traditionally studied in the “looking-while-listening” paradigm (alternatively referred to as the intermodal preferential looking procedure; Fernald, Zangl, Portillo, & Marchman, 2008; Hirsh-Pasek, Cauley, Golinkoff, & Gordon, 1987). 
In such studies, infants listen to a sentence prompting a specific referent (e.g., Look at the dog!) while viewing two images on the screen (e.g., an image of a dog – the target image – and an image of a duck – the distractor image). 
Infants’ word recognition is measured in terms of how quickly and accurately they fixate on the correct target image after hearing its label. 
Past research has used this same basic method to study a wide range of questions in language development. 
For example, the looking-while-listening paradigm has been used to uncover early knowledge of nouns in infants’ early noun knowledge, phonological representations of words, prediction during language processing, and individual differences in language development (Bergelson & Swingley, 2012; Golinkoff, Ma, Song, & Hirsh-Pasek, 2013; Lew-Williams & Fernald, 2007; Marchman et al., 2018; Swingley & Aslin, 2000).

## Measuring developmental change in word recognition
While the looking-while-listening paradigm has been highly fruitful in advancing understanding of early word knowledge, fundamental questions remain both about the trajectory of children’s word recognition ability and the nature of the method itself.
One central question is how to measure developmental change in word recognition. 
A key idea in the language learning literature is that processing speed - the ability to quickly link a word with its referent - supports language learning.
Age-related changes in speed of processing are thought to accelerate infants' subsequent language learning: the faster infants are able to process incoming speech input, the better able they become to learn from their language environment.
Similarly, longitudinal analyses have found that individual differences in word recognition speed predict linguistic and cognitive outcomes later in childhood (e.g., Marchman & Fernald, 2008). 
However, measuring increases in the speed and accuracy of word recognition faces the challenge of distinguishing developmental changes in word recognition skill from changes in knowledge of specific words. 
This problem is particularly thorny in child development, since the number of items that can be tested within a single session is limited and items must be selected in an age-appropriate manner (Peter et al., 2019). 
Measuring developmental change therefore requires large-scale datasets with a range of items, in order to generalize age-related changes across words.

## Developing methodological best-practices
A second question relates to evaluating methodological best practices. In particular, many fundamental analytic decisions vary substantially across studies, and different decisions may lead to different inferences about children’s word recognition. For example, researchers vary in how they select time windows for analysis, transform the dependent measure of target fixations, and model the time course of word recognition (Csibra, Hernik, Mascaro, Tatone, & Lengyel, 2016; Fernald et al., 2008; Huang & Snedeker, 2020). This problem is made more complex by the fact that many of these decisions depend on a variety of design-related and participant-related factors (e.g., infant age). Establishing best practices therefore requires a large database of infant word recognition studies varying across such factors, in order to test the potential consequences of methodological decisions on study results.

## Peekbank: An open database of developmental eye-tracking studies.
What these two questions share is that they are difficult to answer at the scale of a single study. To address this challenge, we introduce Peekbank, a flexible and reproducible interface to an open database of developmental eye-tracking studies. The Peekbank project (a) collects a large set of eye-tracking datasets on children’s word recognition, (b) introduces a data format and processing tools for standardizing eye-tracking data across data sources, and (c) provides an interface for accessing and analyzing the database. In the current paper, we give an overview of the key components of the project and some initial demonstrations of its utility in advancing theoretical and methodological insights. We report two analyses using the database and associated tools (N=1,233): (1) a growth curve analysis modeling age-related changes in infants’ word recognition while generalizing across item-level variability; and (2) a multiverse-style analysis of how a central methodological decision – selecting the time window of analysis – impacts inter-item reliability.

# Design and Technical Approach

## Database Framework.

<!-- 
guiding users through the sections, similar to the childes-db paper 
Need to explain motivations first, such as issues encountered when consolidating multiple experimental design, etc. 
why a unified format is need first, hence the data import and raw data processing
-->

One of the main challenges in compiling a large-scale eye-tracking dataset is the lack of a shared re-usable data format across individual experiments. Researcher conventions for structuring data vary, as do the technical specifications of different devices, rendering the task of integrating datasets from different labs and data sources difficult. Therefore, our first effort was developing a common, tidy format for the eye-tracking data in Peekbank to ease the process of conducting cross-dataset analyses (Wickham et al., 2019). All incoming datasets will be processed into this unified format and then ingested into the core database. 

As illustrated in Figure XX, the Peekbank framework consists of three main components: (1) processing eye-tracking experimental datasets into a unified format; (2) populating a relational database; and (3) providing an interface to the database. These components are supported by three libraries. The peekds library (for the R language; R Development Core Team, 2020) helps researchers convert and validate existing datasets to use the relational format of the database. The peekbank module (Python) creates a database with the relational schema and populates it with the standardized datasets produced by peekds. The database is implemented in MySQL, an industry standard relational database, which may be accessed by a variety of programming languages over the internet. The peekbankr library (R) provides an application programming interface, or API, that offers high-level abstractions for accessing data in Peekbank.

In the following sections, we will begin by providing the details on the database’s scheme design and technical implementation on peekds. For users who are primarily interested in accessing the database can skip these details and focus on access through the peekbankr API and the web apps.


```{r fig-framework-overview, fig.env = "figure", fig.align = "center", fig.height=4.5, set.cap.width=T, num.cols.cap=1, fig.cap = "Overview of the Peekbank data ecosystem. Peekbank tools are highlighted in green. *custom R packages."}
img <- png::readPNG(here("brm/figures","peekbankflowchartv6.png"))

grid::grid.raster(img)
```

## Data Format and Processing.
During data import, raw eye-tracking datasets are processed to conform to the Peekbank data schema. The centerpiece of the schema is the aoi_timepoints table (Fig XX), which records whether participants looked to the target or the distractor stimulus at each timepoint of a given trial. Additional tables track information about data sources, participant characteristics, trial characteristics, stimuli, and raw eye-tracking data. In addition to unifying the data format, we conduct several additional pre-processing steps to facilitate analyses across datasets, including resampling observations to a common sampling rate (40 Hz) and normalizing time relative to the onset of the target label.

```{r fig-schema, fig.env = "figure", fig.align = "center", fig.height=4.5, set.cap.width=T, num.cols.cap=1, fig.cap = "The Peekbank schema. Each square represents a table in the relational database."}
img <- png::readPNG(here("brm/figures","schema_3.png"))

grid::grid.raster(img)
```


## Current Data Sources.

```{r xtable, num.cols.cap=1, results="asis"}
load(file = here("brm","data","dataset_info.Rds"))
load(file = here("brm","data","aoi_data_joined.Rds"))

dataset_name_mapping <- read_csv(here("brm","data","dataset_name_mapping.csv"))
iso_codes <- read_csv(here("brm","data","iso_language_codes.csv"))

dataset_unique_subj <- dataset_info %>%
  distinct(subject_id,sex)

summarize_novel_familiar <- aoi_data_joined %>%
  group_by(dataset_name,stimulus_novelty) %>%
  summarize(n=n()) %>%
  left_join(dataset_name_mapping) %>%
  pivot_wider(id_cols=dataset_rename,names_from = stimulus_novelty,values_from=n) %>%
  group_by(dataset_rename) %>%
  summarize(
    has_familiar = ifelse(is.na(familiar)|familiar==0,0,1),
    has_novel=ifelse(is.na(novel)|novel==0,0,1)
  )

summarize_datasets <- dataset_info %>%
  left_join(dataset_name_mapping) %>%
  group_by(dataset_rename, apa_cite) %>%
  summarize(
    #num_admin=length(unique(administration_id)),
    num_subj=length(unique(subject_id)),
    #percent_female=round(sum(sex=="female")/sum(sex %in% c("female","male")),2),
    avg_age=mean(age,na.rm=T),
    min_age_months = round(min(age, na.rm = TRUE),0), 
    max_age_months = round(max(age, na.rm = TRUE),0),
    method=unique(coding_method)[1],
    native_language = names(which.max(table(native_language)))) %>%
  # mutate(
  #   percent_female = case_when(
  #     is.nan(percent_female) ~ "N/A",
  #     TRUE ~ paste0(percent_female*100,"%"))
  # ) %>%
  mutate(
    method=case_when(
      method=="manual gaze coding" ~ "manual coding",
      method=="eyetracking" ~ "eye-tracking",
      method=="preprocessed eyetracking" ~ "eye-tracking",
      TRUE ~ method)
  ) %>%
    #split language into multiple columns (only two expected; expand if dataset acquires more)
  separate(native_language,into=c("native_language_1","native_language_2"),sep=", ") %>%
  #join based on ISO standard
  left_join(iso_codes,by=c("native_language_1"="iso_code")) %>%
  left_join(iso_codes,by=c("native_language_2"="iso_code")) %>%
  rename(
    language_name_1 = language_name.x,
    language_name_2 = language_name.y
  ) %>%
  #clean up some naming issues
  mutate(
    language_name_1 = case_when(
      language_name_1 == "Spanish; Castilian" ~ "Spanish",
      TRUE ~ language_name_1
    )) %>%
  #unite names
  mutate(
    language = case_when(
      !is.na(language_name_2) ~ paste(language_name_1,language_name_2,sep=", "),
      TRUE ~ language_name_1)) %>%
  # native language special cases
  mutate(
    language = case_when(
      dataset_rename == "tseltal" ~ "Tseltal",
      TRUE ~ language)) %>%
  #convert age range into one column
  mutate(age_range_months= paste(min_age_months,max_age_months,sep=" - ")) %>%
  mutate(
   apa_cite=case_when(
      is.na(apa_cite) ~ "unpublished",
      TRUE ~ apa_cite
  )) %>%
  select(dataset_rename,apa_cite, num_subj,avg_age,age_range_months,method,language) %>%
  arrange(dataset_rename)

summarize_dataset_by_age_bin <- dataset_info %>%
  left_join(dataset_name_mapping) %>%
  mutate(
    age_bin = case_when(
      age <= 24 ~ "(12,24]",
      age <=36 ~ "(24,36]",
      age <=48 ~ "(36,48]",
      age<=60 ~ "(48,60]"
    )
  ) %>%
  group_by(dataset_rename,age_bin) %>%
  summarize(
    num_subj=length(unique(subject_id)))

tab1 <- xtable::xtable(summarize_datasets, digits=c(1), 
                       caption = "Overview over the datasets in the current database.")

names(tab1) <- c("Dataset Name", "Citation","N","Mean Age (mos.)","Age Range (mos.)", "Method", "Language")

align(tab1) <- c("llrrrrrr")

print(tab1, type="latex", comment = F,include.rownames=FALSE, size="\\fontsize{9pt}{10pt}\\selectfont",
scalebox=0.85)
```

The database currently includes 11 looking-while-listening datasets comprising *N*=`r sum(summarize_datasets$num_subj)` total participants (Table XX). Most datasets (10 out of 11 total) consist of data from monolingual native English speakers. They span a wide age spectrum with participants ranging from 8 to 84 months of age, and are balanced in terms of gender (48% female). The datasets vary across a number of dimensions related to design and methodology, and include studies using manually coded video recordings and automated eye-tracking methods (e.g., Tobii, EyeLink) to measure gaze behavior. Most studies focused on testing familiar items, but the database also includes studies with novel pseudowords. All data (and accompanying references) are openly available on the Open Science Framework (https://osf.io/pr6wu/?view_only=07a3887eb7a24643bdc1b2612f2729de).



How selected?
Language coverage?
More details about lab and design variation?

## Versioning + Expanding the database

Information about versioning approach/ regularity of updates
Steps for extending the database?

# Interfacing with peekbank

## Shiny App

One goal of the Peekbank project is to allow a wide range of users to easily explore and learn from the database.
We therefore have created an interactive web application -- \texttt{peekbank-shiny} -- that allows users to quickly and easily create informative visualizations of individual datasets and aggregated data.
\texttt{peekbank-shiny} is built using Shiny, a software package for creating web apps using R.
The Shiny app allows users to create commonly used visualizations of looking-while-listening data, based on data from the Peekbank database.
Specifically, users can visualize 

1. the time course of looking data in a profile plot depicting infant target looking across trial time,
2. overall accuracy (proportion target looking) within a specified analysis window,
3. reaction times (speed of fixating the target image) in response to a target label, and
4. an onset-contingent plot, which shows the time course of participant looking as a function of their look location at the onset of the target label.

Users are given various customization options for each of these visualizations, e.g., choosing which datasets to include in the plots, controlling the age range of participants, splitting the visualizations by age bins, and controlling the analysis window for time course analyses.
Plots are then updated in real time to reflect users' customization choices, and users are given options to share the visualizations they created.
The Shiny app thus allows users to quickly inspect basic properties of Peekbanks datasets and create reproducible visualizations without incurring any of the technical overhead required to access the database through R.

## Peekbankr

Functions:
connect_to_peekbank():
get_datasets()
get_subjects()
get_administrations()
get_stimuli()
get_aoi_timepoints()
get_trials()
get_trial_types()
get_xy_timepoints()
get_aoi_region_sets()

## OSF site
Stimuli
Data in raw format (if some additional datum needed, e.g. pupil size?)

# Peekbank in Action

We provide two potential use-cases for Peekbank data. In each case, we provide sample code so as to model how easy it is to do simple analyses using data from the database. Our first example shows how we can replicate the analysis for a classic study. This type of computational reproducibility can be a very useful exercise for teaching students about best practices for data analysis [e.g., @Hardwicke2018] and also provides an easy way to explore looking-while-listening timecourse data in a standardized format. Our second example showss an in-depth exploration of developmental changes in the recognition of particular words. Besides its theoretical interest (which we will explore more fully in subsequent work), this type of analysis can be used for optimizing the stimuli for new experiments. 

## Computational reproducibility example: Swingley & Aslin (2002)



```{r get_am}

aoi_timepoints <- peekbankr::get_aoi_timepoints(dataset_name = "swingley_aslin_2002", 
                                                
                                         rle=FALSE)
administrations <- peekbankr::get_administrations(dataset_name = "swingley_aslin_2002")

stimuli <- peekbankr::get_stimuli(dataset_name = "swingley_aslin_2002")
trial_types <- peekbankr::get_trial_types(dataset_name = "swingley_aslin_2002")
trials <- peekbankr::get_trials(dataset_name = "swingley_aslin_2002")
```

```{r}
accs <- aoi_timepoints %>%
  left_join(administrations) %>%
  left_join(trials) %>%
  left_join(trial_types) %>%
  filter(condition != "filler") %>%
  mutate(condition = ifelse(condition == "cp", "Correct","Mispronunciation")) %>%
  # mutate(age_group = ifelse(age < mean(age), "13-17", "17-20")) %>%
  group_by(t_norm, administration_id, condition) %>% 
  summarise(correct = mean(aoi == "target") / 
              mean(aoi %in% c("target","distractor"))) %>%
  group_by(t_norm, condition) %>% 
  summarise(ci = 1.96 * sd(correct) / sqrt(length(correct)), 
            correct = mean(correct))

ggplot(accs, aes(x = t_norm, y = correct, col = condition)) + 
  geom_pointrange(aes(ymin = correct - ci, 
                      ymax = correct + ci)) +
  geom_hline(yintercept = .5, lty = 2, col = "black") + 
  langcog::theme_mikabr() + 
  langcog::scale_color_solarized(name = "Age Group") + 
  xlim(-500, 3000) + 
  xlab("Time from target word onset (msec)") + 
  ylab("Proportion correct") + 
  theme(legend.position = "bottom") 
```

## Item analyses

To illustrate the power of aggregating data across multiple datasets, we, 

aspirational goal - 

ALso, item selection but maybe not yet? 

```{r all_data}
all_aoi_timepoints <- peekbankr::get_aoi_timepoints(rle=FALSE)
all_stimuli <- peekbankr::get_stimuli()
all_administrations <- peekbankr::get_administrations()
all_trial_types <- peekbankr::get_trial_types() 
all_trials <- peekbankr::get_trials()  

aoi_data_joined <- all_aoi_timepoints %>%
  right_join(all_administrations) %>%
  right_join(all_trials) %>%
  right_join(all_trial_types) %>%
  mutate(stimulus_id = target_id) %>%
  right_join(all_stimuli) 
```

```{r eval=FALSE}
item_counts <- aoi_data_joined %>%
  group_by(administration_id, english_stimulus_label) %>%
  count() %>%
  group_by(english_stimulus_label) %>%
  count() %>%
  mutate(english_stimulus_label = fct_reorder(english_stimulus_label, n))

ggplot(filter(item_counts, n > 80), 
       aes(x= english_stimulus_label, y = n)) + 
  geom_bar(stat = "identity")+ 
  coord_flip()
```


```{r}
target_words <- c("book","dog","car","frog","apple",
                  "shoe","kitty","cookie","carrot","birdie","banana","ball")

target_word_data <- aoi_data_joined %>%
  filter(english_stimulus_label %in% target_words) %>%
  mutate(age_group = cut(age, breaks = seq(12,48,6))) %>%
  filter(!is.na(age_group)) %>%
  group_by(t_norm, administration_id, age_group, english_stimulus_label) %>% 
  summarise(correct = mean(aoi == "target") / 
              mean(aoi %in% c("target","distractor"), na.rm=TRUE)) %>%
  group_by(t_norm, age_group, english_stimulus_label) %>% 
  summarise(ci = 1.96 * sd(correct, na.rm=TRUE) / sqrt(length(correct)), 
            correct = mean(correct, na.rm=TRUE), 
            n = n()) 

p <- ggplot(filter(target_word_data, n > 60), 
       aes(x = t_norm, y = correct, col = age_group)) + 
  geom_line() + 
  geom_linerange(aes(ymin = correct - ci, ymax = correct + ci), 
                 alpha = .2) + 
  ylim(.35,1) + 
  facet_wrap(~english_stimulus_label) + 
  geom_hline(yintercept = .5, lty = 2, col = "black") + 
  langcog::theme_mikabr() + 
  langcog::scale_color_solarized(name = "Age Group (months)") + 
  xlim(0, 4000) + 
  xlab("Time from target word onset (msec)") + 
  ylab("Proportion correct") + 
  theme(legend.position = "bottom")

```
## Links to parent report vocabulary data

```{r}
items <- wordbankr::get_item_data(language = "English (American)") %>%
  filter(definition %in% target_words)
ws_data <- wordbankr::get_instrument_data(language = "English (American)", 
                                          form = "WS", 
                                          administrations = TRUE, 
                                          items = items$item_id[items$form == "WS"]) %>%
  right_join(items)
wg_data <- wordbankr::get_instrument_data(language = "English (American)", 
                                          form = "WG", 
                                          administrations = TRUE, 
                                          items = items$item_id[items$form == "WG"]) %>%
  right_join(items)

wordbank_data <- bind_rows(ws_data, wg_data) %>%
  mutate(produces = value == "produces", 
         form = "both", 
         num_item_id = definition, # stupid stuff to make fit_aoa work on joint data
         item_id = definition) 

aoas <- wordbankr::fit_aoa(wordbank_data, 
                           measure = "produces", 
                           method = "glmrob",
                           age_min = 8, 
                           age_max = 36)
```


```{r}
wb_pb <- target_word_data %>%
  filter(t_norm > 300, t_norm < 3000, n > 20) %>%
  group_by(age_group, english_stimulus_label) %>%
  summarise(accuracy = mean(correct)) %>%
  left_join(select(aoas, definition, aoa) %>% 
              rename(english_stimulus_label = definition))

ggplot(wb_pb, 
       aes(x = aoa, y = accuracy, col = english_stimulus_label))+
  geom_point() + 
  facet_wrap(~age_group)+
  geom_smooth(aes(group = 1), method = "lm")
```



# Discussion/ Conclusion

Theoretical progress in understanding child development requires rich datasets, but collecting child data is expensive, difficult, and time-intensive. Recent years have seen a growing effort to build open source tools and pool research efforts to meet the challenge of building a cumulative developmental science (Bergmann et al., 2018; Frank, Braginsky, Yurovsky, & Marchman, 2017; The ManyBabies Consortium, 2020). The Peekbank project expands on these efforts by building an infrastructure for aggregating eye-tracking data across studies, with a specific focus on the looking-while-listening paradigm. This paper presents an illustration of some of the key theoretical and methodological questions that can be addressed using Peekbank: generalizing across item-level variability in children’s word recognition and providing data-driven guidance on methodological choices.

There are a number of limitations surrounding the current scope of the database. A priority in future work will be to expand the size of the database. With 11 datasets currently available in the database, idiosyncrasies of particular designs and condition manipulations still have substantial influence on modeling results. Expanding the set of distinct datasets will allow us to increase the number of observations per item across datasets, leading to more robust generalizations across item-level variability. The current database is also limited by the relatively homogeneous background of its participants, both with respect to language (almost entirely monolingual native English speakers) and cultural background (all but one dataset comes from WEIRD populations; Muthukrishna et al., 2020). Increasing the diversity of participant backgrounds and languages will expand the scope of the generalizations we can form about child word recognition. 
Finally, while the current database is focused on studies of word recognition, the tools and infrastructure developed in the project can in principle be used to accommodate any eye-tracking paradigm, opening up new avenues for insights into cognitive development. Gaze behavior has been at the core of many of the key advances in our understanding of infant cognition. Aggregating large datasets of infant looking behavior in a single, openly-accessible format promises to bring a fuller picture of infant cognitive development into view.

# Acknowledgements
We would like to thank the labs and researchers that have made their data publicly available in the database.

We used `r cite_r("peekbank.bib")` for all our analyses.


\newpage

# References

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id="refs" custom-style="Bibliography"></div>
\endgroup
