---
title: "Peekbank Item Prediction - Building from Base Model"
author: "Martin Z"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    code_folding: hide
    toc: true
    toc_depth: 4
    toc_float: true
---


```{r, message=F, warning=F}
library(knitr)
library(peekbankr)
library(tidyverse)
library(lme4)
library(lmerTest)
library(tictoc)
library(langcog)
library(here)
#library(tidymodels)
library(wordbankr)
#devtools::install_github("tidymodels/multilevelmod")
#library(multilevelmod)

figure_path <- here("figures")

load(file = "data/aoi_data_joined.Rds")
knitr::opts_chunk$set(cache = TRUE, warning = FALSE, message = FALSE)
dataset_name_mapping <- read_csv(here("data","dataset_name_mapping.csv"))

con <- connect_to_peekbank()
stimuli <- get_stimuli(connection = con) %>% collect()
subjects <- get_subjects(connection = con) %>% collect()

aoi_data_joined <- aoi_data_joined %>%
  left_join(subjects)


```

The goal is to explore relationships between item-level properties (specifically, child-directed word frequency and age of acquisition) and accurate looking in the looking while listening paradigm across age.

## Preparing the data 

### Fit and filter trial accuracy (proportion looking to target)

Compute trial-level accuracy (proportion looking to the target) in a fixed critical window (300-2000ms).

We are focusing only on 

* familiar words

* ages between 12-60 months

* English datasets (since this is what we have norms for)

```{r}
t_min <- 300
t_max <- 2000

by_trial_means <- aoi_data_joined %>%
  #remove dataset
  #filter(dataset_name!="pomper_saffran_2016") %>%
  #restrict to english datasets
  filter(native_language == "eng") %>%
  #restrict age range
  filter(age > 12, age <= 60) %>%
  # familiar target items only %>%
  filter(stimulus_novelty == "familiar") %>%
  #window of analysis
  filter(t_norm > t_min, t_norm < t_max) %>%
  mutate(age_binned = cut(age, seq(12,60,12))) %>%
  rename(target_label = english_stimulus_label) %>%
  group_by(administration_id, trial_id, target_label, distractor_id, 
           age, age_binned) %>%
  summarise(prop_looking = sum(aoi == "target", na.rm = TRUE) / 
              (sum(aoi == "target", na.rm=TRUE) + 
                 sum(aoi=="distractor", na.rm=TRUE)),
            prop_missing = mean(aoi == "missing", na.rm = TRUE)) %>%
  left_join(stimuli, by = c("distractor_id" = "stimulus_id")) %>%
  rename(distractor_label = english_stimulus_label)
  
```

Filter the data to trials where there is sufficient looking data (target or distractor looking on at least 2/3 of the trial)

```{r}
acc_mod_data <- by_trial_means %>%
  ungroup() %>%
  filter(prop_missing < 1/3) %>%
  mutate(age_centered = age - mean(age,na.rm=TRUE))

target_label_counts <- acc_mod_data %>%
  ungroup() %>%
  group_by(target_label) %>%
  summarize(
    trial_count=n()
  )

acc_mod_data <- acc_mod_data %>%
  left_join(target_label_counts)

```

### Add English Frequency Info

Frequency information using childes-db. Updated Frequency values cleaned (e.g. polysemy, diminutives etc.)

```{r,eval=FALSE}
write_csv(acc_mod_data %>%select(target_label) %>% rename(label=target_label) %>% distinct()
          ,here("data","target_label_items_unique.csv"))

freq <- read_csv(here("data/childes_english_word_freq_cleaned.csv")) %>%
  #unify various word forms
  ## TODO unify lemmas (plurals, etc.)
  mutate(word_unified = case_when(
    word  %in% c("doggie","doggy") ~ "doggy",
    word %in% c("birdie","birdy") ~ "birdie",
    word %in% c("diapie", "diaper") ~ "diaper",
    word %in% c("phone","telephone") ~ "phone",
    word %in% c("sock","socks") ~ "sock",
    word %in% c("shoe","shoes") ~ "shoe",
    word %in% c("blueberry","blueberries") ~ "blueberry",
    word %in% c("bike","bicycle") ~ "bike",
    word %in% c("block","blocks") ~ "blocks",
    TRUE ~ tolower(word)
  )) %>%
  group_by(word_unified) %>%
  summarize(
    word_count_unified=sum(word_count)
  )

write.csv(freq
          ,here("data","childes_freq_mapped_cleaned.csv"))
```

Read in and join cleaned frequencies

```{r}
#read in mapping of target labels for joining on frequency
unique_labels_freq <- read_csv(here("data","target_label_items_unique_mapping.csv")) %>% select(label,label_for_freq)

acc_mod_data <- acc_mod_data %>%
  left_join(unique_labels_freq, by=c("target_label"="label")) %>%
  rename(target_label_freq=label_for_freq) %>%
  left_join(unique_labels_freq, by=c("distractor_label"="label")) %>%
  rename(distractor_label_freq=label_for_freq)

#read in cleaned frequency info
freq <- read_csv(here("data","childes_freq_mapped_cleaned.csv"))  

#remove the following items due to polysemy issues
items_to_remove <- c("tablet","can")

#join to proportion looking data
acc_mod_freq <- left_join(acc_mod_data, 
                      select(freq,word_unified, word_count_unified),by = c("target_label_freq" = "word_unified")) %>%
  filter(!(target_label_freq %in% items_to_remove)) %>%
  filter(!is.na(target_label_freq)) %>%
  rename(target_word_count=word_count_unified) %>%
  left_join(select(freq,word_unified, word_count_unified),by = c("distractor_label_freq" = "word_unified")) %>%
  filter(!is.na(distractor_label_freq)) %>%
  filter(!(distractor_label_freq %in% items_to_remove)) %>%
  rename(distractor_word_count=word_count_unified) %>%
  ungroup() %>%
  mutate(target_log_freq = log(target_word_count), 
         distractor_log_freq = log(distractor_word_count)) %>%
  mutate(target_log_freq_centered = target_log_freq-mean(target_log_freq,na.rm=TRUE),
         distractor_log_freq_centered = distractor_log_freq-mean(distractor_log_freq,na.rm=TRUE)) %>%
  mutate(luce_log_freq = target_log_freq/ (target_log_freq+distractor_log_freq)) 

by_target_item_means <- acc_mod_freq %>%
  ungroup() %>%
  group_by(target_label_freq,target_word_count,target_log_freq,age_binned) %>%
  summarise(
    N=n(),
    mean_prop_looking=mean(prop_looking,na.rm=TRUE)
  )
```

Histogram of trial frequency by item - Phew! A few items with a LOT of trials

```{r}
ggplot(by_target_item_means,aes(N))+
  geom_histogram()
```


Plot the histogram of Word Frequency

```{r}
ggplot(by_target_item_means,aes(target_log_freq))+
  geom_histogram()
```

### Collect English AOA Information

Run this code chunk to collect AOA information from the English (American) WS form on Wordbank. After identifying target labels that cannot be found on Wordbank, a .csv is exported to resolve inconsistencies by hand (e.g. "chicken" == "chicken (animal)" in Wordbank).

```{r,eval = FALSE}
items_for_aoa <- unique(acc_mod_data$target_label)
#get wordbank items
wordbank_items_eng_ws <- get_item_data(language = "English (American)", form = "WS")
#compare to target label names
setdiff(items_for_aoa,wordbank_items_eng_ws$definition)
#output set difference for manual processing
write_csv(data.frame(target_label=setdiff(items_for_aoa,wordbank_items_eng_ws$definition)),here("data","items_dropped_aoa.csv"))

#set up and read in mapping file w/ aligned definitions for worddbank
stimulus_label_wordbank_intersect <- data.frame(
  target_label=intersect(items_for_aoa,wordbank_items_eng_ws$definition),
  definition=intersect(items_for_aoa,wordbank_items_eng_ws$definition))
stimulus_label_wordbank_mapping <- read_csv(here("data","stimulus_label_wordbank_mapping.csv"))
stimulus_label_wordbank <- bind_rows(stimulus_label_wordbank_intersect,stimulus_label_wordbank_mapping)

item_names_for_wordbank <- stimulus_label_wordbank$definition[!is.na(stimulus_label_wordbank$definition)]

items_for_wordbank <- filter(wordbank_items_eng_ws,definition %in% c(item_names_for_wordbank))$item_id

#get instrument data for target label items from wordbank
eng_ws_data <- get_instrument_data(language = "English (American)",
                                   form = "WS",
                                   items = items_for_wordbank,
                                   administrations=TRUE,
                                   iteminfo=TRUE)

#fit AOA curves to obtain AOA estimates (logistic regression)
aoas_ws_produces <- fit_aoa(eng_ws_data,measure="produces", age_min=0) %>%
  ungroup() %>%
  select(aoa,item_id,definition) %>%
  left_join(stimulus_label_wordbank) %>%
  select(target_label,definition,aoa)

write_csv(aoas_ws_produces,here("data","aoas_wordbank_ws_produces.csv"))
```

### Add English AOAs

Join English AOAs into the trial-level accuracy data, both for target labels and for distractor labels.

```{r}
#aoas <- read_csv(here("data","bglm_aoas_english.csv")) 
aoas <- read_csv(here("data","aoas_wordbank_ws_produces.csv"))

acc_mod_freq_aoa <- left_join(acc_mod_freq, 
                      aoas) %>% #%>%
                        # transmute(target_label = definition, 
                        #           target_aoa = bglm_aoa, 
                        #           target_category = category)) %>%
  rename(target_aoa=aoa) %>%             
  left_join(aoas, by = c("distractor_label" = "target_label")) %>%
  rename(distractor_aoa = aoa) %>%
  filter(!is.na(target_aoa), !is.na(distractor_aoa)) %>%
  # filter(!is.na(target_label_freq),!is.na(distractor_label_freq)) %>%
  ungroup() %>%
  mutate(target_aoa_centered = target_aoa - mean(target_aoa,na.rm=TRUE), 
         distractor_aoa_centered = distractor_aoa - mean(distractor_aoa,na.rm=TRUE)) %>%
  mutate(inverse_target = 1/target_aoa,
         inverse_distractor = 1/distractor_aoa,
         luce_untransformed=target_aoa/(target_aoa+distractor_aoa),
         luce = inverse_target / (inverse_target + inverse_distractor),
         luce_log = log(inverse_target) / (log(inverse_target) + log(inverse_distractor)))
```

## Frequency {.tabset}

First, we're going to explore whether the log word frequency of the relevant items (from CHILDES) predicts proportion target looking. 
We'll look at just the target word frequency first, and then more complex models that also include distractor label frequency. 
The crux is that although it appears that there is some signal here (see plots below), that signal doesn't generalize across items (i.e., once random effects for items are added into the model).
This is probably the result of a few different things coming together:

1. We have vastly different numbers of observations for different items

2. There are idiosyncrasies to these datasets, and one or two datasets with a distinct set of items can have a vast amount of influence at this point.

3. The items are not randomly distributed across e.g., age, but are specifically selected for the age range tested, so there is significant range restriction likely going on.

### Plots {.tabset}

#### general correlation

```{r}
#by age bin
acc_mod_freq %>%
  ggplot(aes(target_log_freq,prop_looking))+
  geom_point(alpha=0.01)+
  geom_smooth(method="lm")
```

#### By Age Bin

```{r}
#by age bin
acc_mod_freq %>%
  ggplot(aes(target_log_freq,prop_looking))+
  geom_point(alpha=0.01)+
  geom_smooth(method="lm")+
  facet_wrap(~age_binned)
```
#### By Dataset

```{r}
#by dataset
acc_mod_freq %>%
  ggplot(aes(target_log_freq,prop_looking))+
  geom_point(alpha=0.01)+
  geom_smooth(method="lm")+
  facet_wrap(~dataset_name)
```

#### Plot summarized Items

This plot shows relationships between frequency and proportion target looking when averaging across trials for each specific item.

```{r}
n_cutoff <- 20
by_target_item_means %>%
  filter(N>n_cutoff) %>%
  ggplot(aes(target_log_freq,mean_prop_looking,size=N,color=target_label_freq))+
  geom_point()+
  geom_smooth(method="lm",color="black")+
  theme(legend.position="none")+
  facet_wrap(~age_binned)
```

### Frequency - Building Base Model {.tabset}

Sequentially build the best non-item driven model (age/ dataset/ participant-based variance only) of proportion-looking to target.

#### Dataset & Administration Random Intercepts

```{r}
m0 <- lmer(prop_looking ~ 1+(1|administration_id)+(1|dataset_name), data = acc_mod_freq)
summary(m0)
```

#### Add Age Fixed Effect

Adding age as a fixed effect significantly improves model fit

```{r}
m1 <- lmer(prop_looking ~ age_centered+(1|administration_id)+(1|dataset_name), data = acc_mod_freq)
summary(m1)
anova(m1,m0)
```

#### Add Age by dataset random slope

Age by-dataset random slope does not improve fit (and singular fit warning - high covariance between age and intercept)

```{r}
m2 <- lmer(prop_looking ~ age_centered+(1|administration_id)+(1+age_centered|dataset_name), data = acc_mod_freq)
summary(m2)
anova(m1,m2)
```
#### Set Base model

```{r}
m_base <- m1
```

### Adding by-item random intercepts {.tabset}

#### Target label random intercept greatly improves model fit

```{r}
m3 <-  lmer(prop_looking ~ age_centered+(1|administration_id)+(1|dataset_name)+ (1|target_label_freq), data = acc_mod_freq)
summary(m3)
anova(m_base,m3)
```

#### Distractor label random intercept greatly improves model fit

```{r}
m4 <-  lmer(prop_looking ~ age_centered+(1|administration_id)+(1|dataset_name)+ (1|target_label_freq)+(1|distractor_label_freq), data = acc_mod_freq)
summary(m4)
anova(m3,m4)
```

#### Set base item model

```{r}
m_base_item <- m4
```

### Add in frequency fixed effects {.tabset}

#### Target Frequency

```{r}
m5 <-  lmer(prop_looking ~ target_log_freq_centered + age_centered+(1|administration_id)+(1|dataset_name)+ (1|target_label_freq)+(1|distractor_label_freq), data = acc_mod_freq)
summary(m5)
anova(m_base_item,m5)
```
#### Distractor Frequency

```{r}
m6 <-  lmer(prop_looking ~ distractor_log_freq_centered + age_centered+(1|administration_id)+(1|dataset_name)+ (1|target_label_freq)+(1|distractor_label_freq), data = acc_mod_freq)
summary(m6)
anova(m_base_item,m6)
```

#### Both

```{r}
m7 <-  lmer(prop_looking ~ target_log_freq_centered +distractor_log_freq_centered + age_centered+(1|administration_id)+(1|dataset_name)+ (1|target_label_freq)+(1|distractor_label_freq), data = acc_mod_freq)
summary(m7)
anova(m_base_item,m7)
```

## AOA+Frequency {.tabset}

### AOA+Frequency - Building Base Model {.tabset}

Sequentially build the best non-item driven model (age/ dataset/ participant-based variance only) of proportion-looking to target (this time with the dataset with AOAs joined in)

#### Dataset & Administration Random Intercepts

```{r}
m0 <- lmer(prop_looking ~ 1+(1|administration_id)+(1|dataset_name), data = acc_mod_freq_aoa)
summary(m0)
```

#### Add Age Fixed Effect

Adding age as a fixed effect significantly improves model fit

```{r}
m1 <- lmer(prop_looking ~ age_centered+(1|administration_id)+(1|dataset_name), data = acc_mod_freq_aoa)
summary(m1)
anova(m1,m0)
```

#### Add Age by dataset random slope

Age by-dataset random slope does not improve fit (and singular fit warning - high covariance between age and intercept)

```{r}
m2 <- lmer(prop_looking ~ age_centered+(1|administration_id)+(1+age_centered|dataset_name), data = acc_mod_freq_aoa)
summary(m2)
anova(m1,m2)
```
#### Set Base model

```{r}
m_base <- m1
```

### Adding by-item random intercepts {.tabset}

#### Target label random intercept greatly improves model fit

```{r}
m3 <-  lmer(prop_looking ~ age_centered+(1|administration_id)+(1|dataset_name)+ (1|target_label_freq), data = acc_mod_freq_aoa)
summary(m3)
anova(m_base,m3)
```

#### Distractor label random intercept greatly improves model fit

```{r}
m4 <-  lmer(prop_looking ~ age_centered+(1|administration_id)+(1|dataset_name)+ (1|target_label_freq)+(1|distractor_label_freq), data = acc_mod_freq_aoa)
summary(m4)
anova(m3,m4)
```

#### Set base item model

```{r}
m_base_item <- m4
```

### Add in AOA fixed effects {.tabset}

#### Target AOA

Adding Target AOA as a fixed effect does not improve fit

```{r}
m5 <-  lmer(prop_looking ~ target_aoa_centered + age_centered+(1|administration_id)+(1|dataset_name)+ (1|target_label_freq)+(1|distractor_label_freq), data = acc_mod_freq_aoa)
summary(m5)
anova(m_base_item,m5)
```
#### Distractor AOA

Distractor AOA does not improve fit

```{r}
m6 <-  lmer(prop_looking ~ distractor_aoa_centered + age_centered+(1|administration_id)+(1|dataset_name)+ (1|target_label_freq)+(1|distractor_label_freq), data = acc_mod_freq_aoa)
summary(m6)
anova(m_base_item,m6)
```

#### Both

```{r}
m7 <-  lmer(prop_looking ~ target_aoa_centered +distractor_aoa_centered + age_centered+(1|administration_id)+(1|dataset_name)+ (1|target_label_freq)+(1|distractor_label_freq), data = acc_mod_freq_aoa)
summary(m7)
anova(m_base_item,m7)
```

#### Luce

```{r}
m8 <-  lmer(prop_looking ~ luce + age_centered+(1|administration_id)+(1|dataset_name)+ (1|target_label_freq)+(1|distractor_label_freq), data = acc_mod_freq_aoa)
summary(m8)
anova(m_base_item,m8)
```

### Add in AOA and Frequency fixed effects {.tabset}

#### Target AOA and Frequency

```{r}
m9 <-  lmer(prop_looking ~ target_aoa_centered + target_log_freq_centered+ age_centered+(1|administration_id)+(1|dataset_name)+ (1|target_label_freq)+(1|distractor_label_freq), data = acc_mod_freq_aoa)
summary(m9)
anova(m_base_item,m9)
```

#### Target+Distractor AOA and Frequency

```{r}
m10 <-  lmer(prop_looking ~ target_aoa_centered +distractor_aoa_centered + target_log_freq_centered+distractor_log_freq_centered+ age_centered+(1|administration_id)+(1|dataset_name)+ (1|target_label_freq)+(1|distractor_label_freq), data = acc_mod_freq_aoa)
summary(m10)
anova(m_base_item,m9,m10)
```