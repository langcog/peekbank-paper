---
title: "Time Window Analysis"
author: "windowing team"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Motivation

[Peelle and Van Engen (2020)](https://psyarxiv.com/pc3da/) style multiverse analysis considering possible time windows with logistic growth curve models in a dataset with words of varying frequency, stimuli with varying levels of noise, and with young or old adults. 

```{r load-packages, echo=F, message=F, warning=F}
# change t_range upper limit to 4000 for full window analysis

library(tidyverse)
library(tictoc)
library(langcog)
library(doParallel)
library(foreach)
library(ggpubr)
library(purrr)

RUN_MODELS = FALSE
```

For our analysis, we will restrict ourselves to familiar words, and will model age effects.

```{r load-data, eval=RUN_MODELS}
# get local copy by running peekbank_explore.Rmd
load("data/aoi_data_joined.Rds")

fam_data <- aoi_data_joined %>%
  filter(age > 12, age <= 60, 
         stimulus_novelty == "familiar",
         dataset_name!="mahr_coartic") %>% # (only has endTimes up to 1800ms)
  mutate(age_binned = cut(age, seq(0,60,12))) 

#overview of administrations for each dataset at a given age bin
fam_data_admin_summary <- fam_data %>%
  group_by(dataset_name, age_binned) %>%
  summarize(N=length(unique(administration_id)))

rm(aoi_data_joined)
```


## Run Window Models


```{r, eval=RUN_MODELS}
# t_norm = [-1000,4000] 
get_alpha <- function (df) {
                    dfw <- pivot_wider(df,
                                       names_from = english_stimulus_label,
                                       values_from = prop_corr) %>%
                      select(-administration_id)
                    alphas <- psych::alpha(dfw)
                    return(alphas$total$raw_alpha)
}

# inter-item correlations
get_interitem <- function (df) {
   dfw <- pivot_wider(df,
                      names_from = english_stimulus_label,
                      values_from = prop_corr) %>%
     ungroup() %>%
     select(-administration_id)
   corrs <- corrr::correlate(dfw)
   mean_corr <- mean(rowMeans(select(corrs, -term), na.rm=TRUE), na.rm=TRUE)
   rm(corrs)
   return(mean_corr)
}

```

```{r tidy-version, eval=RUN_MODELS}

# Time bins are 25 ms 
startTs <- seq(from = -300, to = 1500, by = 25) 
# could use min(pb datasets min time) and max(pb datasets max time)
#windowLengths <- seq(from = 300, to = 2500, by = 25)
endTs <- seq(from = 0, to = 4000, by = 25)

param.grid <- expand_grid(startTs, endTs) %>%
   rename(startTimes = startTs, endTimes = endTs) %>%
   filter((endTimes - startTimes) > 25)

do_interitem_analysis <- function(startTime, endTime, fam_data) {
   print(paste(startTime, endTime))
      fam_data %>% filter(t_norm > startTime, 
                          t_norm < endTime) %>%
         group_by(dataset_name, age_binned, administration_id, english_stimulus_label) %>%
         summarise(prop_corr = sum(aoi == "target") /
                      sum(aoi %in% c("target", "distractor"))) %>%
         group_by(dataset_name, age_binned) %>%
        mutate(n=length(unique(administration_id))) %>%
        group_by(dataset_name, age_binned,n) %>%
        #only keep datasets that are contributing at least 5 admiinistrations (effectively, subjects) to the age bin
        filter(n>=5) %>%
         nest() %>%
         mutate(interitem =  lapply(data, quietly(get_interitem)),
                interitem = interitem[[1]]$result) %>%
         select(-data) %>%
         unnest(cols = "interitem") %>%
         group_by(age_binned) %>%
         summarise(mean = mean(interitem, na.rm=TRUE)) %>%
         mutate(startTime = startTime,
                endTime = endTime)
}

# test
#do_interitem_analysis(-300, 0)


mout <- map2_dfr(param.grid$startTimes, param.grid$endTimes, 
             do_interitem_analysis, fam_data)
# `summarise()` regrouping output by 'dataset_name', 'age_binned', 'administration_id' (override with `.groups` argument)
# `summarise()` ungrouping output (override with `.groups` argument)

# this should also work, but does not
#mout <- param.grid %>% map2_dfr(startTimes, endTimes, 
#             do_interitem_analysis)
# Error in as_mapper(.f, ...) : object 'endTimes' not found


write.csv(mout, file="data/time-window-results.csv")      

```


### Cross-validation

Leave one dataset out, evaluate correlation


```{r cross-validation, eval=RUN_MODELS, message=F}
cv_results <- list()
for(dset in unique(fam_data$dataset_name)) {
   dat <- fam_data %>% filter(dataset_name != dset)
   cv_results[[dset]] <- map2_dfr(param.grid$startTimes, param.grid$endTimes, 
             do_interitem_analysis, dat)
}

save(cv_results, file="data/time_window_cv.Rdata")
```

```{r eval-cv-results, eval=RUN_MODELS}
# correlate ICCs with each left-out dataset with each other left-out dataset
# (maybe we really just want total ICCs vs. with each dataset left out)
cor_mat <- matrix(NA, nrow=length(cv_results), ncol=length(cv_results))
colnames(cor_mat) = names(cv_results)
rownames(cor_mat) = names(cv_results)

for(i in names(cv_results)) {
   for(j in names(cv_results)) {
      if(i!=j) cor_mat[i,j] = cor(cv_results[[i]]$mean, cv_results[[j]]$mean)
   }
}

cor_mat %>% kableExtra::kable(digits=2)
```


Below we show the correlations and sum of squared error between the ICCs from the full dataset vs. with each dataset held out. 
Holding out attword has the largest influence, and holding out reflook_v4 also shows some deviation.
We will visualize the ICCs with each of these datasets held out and try to characterize their influence.

```{r, echo=F}
# all data
mout <- read.csv("data/time-window-results.csv")
#mout <- read.csv("cogsci2021/data/time-window-results.csv", sep=' ')
```

```{r, echo=F}
load("data/time_window_cv.Rdata")
cors = rep(NA, length(names(cv_results)))
mses = rep(NA, length(names(cv_results)))


for(i in 1:length(cv_results)) {
   cors[i] = cor(cv_results[[i]]$mean, mout$mean)
   mses[i] = sum((cv_results[[i]]$mean - mout$mean)^2) # / nrow(mout)
}

cv_dat <- data.frame(held_out_data = names(cv_results),
                     r = cors,
                     SSE = mses)

cv_dat %>% arrange(desc(SSE)) %>%
   kableExtra::kable(digits=3)
```



## Visualization 

```{r load-model-results, echo=F}

plot_interitem <- function(dat, title) {
  dat %>% 
    ggplot(aes(x = startTime, y = endTime, fill = mean)) +
      geom_raster() +
      theme_bw() +
      theme(panel.grid.major = element_blank(), panel.grid.minor = element_blank()) +
      #coord_equal() + 
      scale_fill_gradient2(low = "blue", mid = "white", high = "red") +
      xlab("Start Time (ms)") +
      ylab("End Time (ms)") +
      facet_wrap( ~ age_binned)# +
      #ggtitle(title) 
   #ggsave("figures/interitem_cors_window_analysis.png", width=8,height=5)
}

```


Visualize inter-item correlation (per-subject, dataset, and age-bin) as a function of start time and window length.


```{r visualize-start-window-length, fig.width=8, fig.height=5, echo=F}
plot_interitem(mout, "Inter-item Correlations")
ggsave(file="figures/interitem_cors_window_analysis.png", width=8, height=5)
```

### ICCs without attword

```{r visualize-start-window-length-attword, fig.width=8, fig.height=5, echo=F}
plot_interitem(cv_results$attword_processed, "Inter-item Correlations")
```

Without attword, the strongest ICCs (in 48-60 month-olds at short, early time windows) generally disappear, and ICCs increase at later end times for this oldest age group.

### ICCs without reflook_v4

```{r visualize-start-window-length-reflook, fig.width=8, fig.height=5, echo=F}
plot_interitem(cv_results$reflook_v4, "Inter-item Correlations")
```

Without reflook_v4, again the changes are mostly in the oldest age group: early start times and late end times (upper left of bottom right panel) show ICCs close to 0 (instead of positive).



*Maybe annotate the region that we recommend?*

## Additional analyses

What is the overall relationship between strength of correlation and start time, end time, or window length?

```{r}
mout <- mout %>% mutate(windowLength = endTime - startTime) 
# summary(lm(data=mout, mean ~ startTime +  windowLength))

cor(mout[,2:5])[1,2:4]
```

Correlations only among the positive IICs:

```{r}
prop_positive = length(which(mout$mean>0)) / nrow(mout) # 92.6% positive
hist(mout$mean)
mout_pos <- mout %>% filter(mean > 0)
cor(mout_pos[,2:5])[1,2:4]
```

`r round(prop_positive, 2)` of the time windows investigated resulted in positive IICs, and the median IIC from all simulations was `r round(median(mout$mean),2)`.
The correlations of IIC with start time, end time, and window length are shown above: end time is most predictive of higher IIC.

### Recommendations

Where do we get bad ICCs? (<.01 -- should we consider a higher threshold? e.g. median IIC)

```{r}
#require(GGally)
mout_neg <- mout %>% filter(mean < 0.01)
#ggpairs(mout_neg, columns=2:5, aes(color=age_binned), alpha=.3)
summary(mout_neg)
start_lt300 = length(which(mout_neg$startTime < 300)) / nrow(mout_neg)
start_lt500 = length(which(mout_neg$startTime < 500)) / nrow(mout_neg) 

# condition on start time at least 300ms like reasonable researchers? 
# which(mout_neg$startTime >= 300 & 
winLength_lt1500 = length(which(mout_neg$windowLength < 1500)) / nrow(mout_neg) # .94
win1500_start300 = length(which(mout_neg$startTime >= 300 & mout_neg$windowLength >= 1500)) / nrow(mout_neg)

rec_settings_iic_avg = mean(subset(mout, startTime>=500 & windowLength>=1500)$mean)
```

`r 100*round(start_lt300, 2)`% of low IICs (<.01) had start times <300ms, but pushing the start time out to at least 500 ms eliminated `r 100*round(start_lt500, 2)`% of the low IICs.
A window length of at least 1500 ms eliminated `r 100*round(winLength_lt1500, 2)`% of low ICCs, and this threshold combined with a start time of at least 300 ms eliminated all but `r 100*round(win1500_start300, 3)`% of low ICCs. 
A start time of 500 ms and a window of at least 1500 ms resulted in no IICs < .01, and an average IIC of `r round(rec_settings_iic_avg, 2)`.

