---
title: "Trial analysis 1: Data loading"
author: "Mike"
date: "2/19/2021"
output: 
  html_document:
    toc: true
    toc_depth: 2
    toc_float: true
    code_folding: hide

---

```{r setup, echo = FALSE}
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(peekbankr))
suppressPackageStartupMessages(library(lme4))
suppressPackageStartupMessages(library(ggpmisc))
suppressPackageStartupMessages(library(ggrepel))
suppressPackageStartupMessages(library(ggthemes))

# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed, cache = TRUE, 
                      message=FALSE, warning=FALSE, error=FALSE)

```


This markdown documents a new way of thinking about modeling variation in LWL data. The idea is to try to:

1. extract a summary statistic for each trial
2. model these summaries with LMMs of various types

The trouble is, what's the right summary statistic? It might be that there's not just one! But let's assume there is one and we just need to sum it up right. 

So we'll start by trying to figure out what the best measure is. We're going to make decisions to maximize within-experiment reliability via ICCs.

We're focused on familiar words here. 

## Get data

```{r, eval=FALSE}
all_aoi_timepoints <- get_aoi_timepoints()
all_stimuli <- get_stimuli()
all_administrations <- get_administrations()
all_subjects <- get_subjects()
all_trial_types <- get_trial_types() 
all_trials <- get_trials() 

aoi_data_joined <- all_aoi_timepoints |>
  right_join(all_administrations) |>
  right_join(all_subjects) |>
  right_join(all_trials) |>
  right_join(all_trial_types) |>
  mutate(stimulus_id = target_id) |>
  right_join(all_stimuli) |>
  select(dataset_name, subject_id, administration_id, trial_id, dataset_id, 
         stimulus_id, distractor_id, t_norm, age, aoi, english_stimulus_label, 
         stimulus_novelty) %>%
  rename(target_label = english_stimulus_label) %>%
  left_join(all_stimuli %>%
              select(stimulus_id, dataset_id, 
                     stimulus_novelty, english_stimulus_label) %>%
              rename(distractor_id = stimulus_id, 
                     distractor_novelty = stimulus_novelty,
                     distractor_label = english_stimulus_label))
  
# TO DO: looks like a very small number of rows get added in the join, probably a sign of an issue/ ambiguity somewhere.
```


Take only familiar word data. 
(Note: retaining monolingual+bilingual data; only excluding Tseltal dataset)

```{r}
d_trial <- aoi_data_joined |>
  filter(dataset_name != "casillas_tseltal_2015") |>
  filter(age > 12, age <= 60, 
         stimulus_novelty == "familiar",
         distractor_novelty == "familiar") |> 
  select(dataset_name, subject_id, administration_id, trial_id, 
         dataset_id, stimulus_id, t_norm, age, aoi, target_label, distractor_label) |>
  mutate(correct = ifelse(aoi == "target", 1, 
                          ifelse(aoi == "distractor", 0, NA)))

save(d_trial, file = here("explorations","data","d_trial.Rds"))

```


