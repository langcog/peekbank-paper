---
title: "Trial analysis 3: modeling individual trials"
author: "Mike"
date: "2/19/2022"
output: html_document
---

```{r setup, echo = FALSE}
suppressPackageStartupMessages(library(here))
suppressPackageStartupMessages(library(tidyverse))
suppressPackageStartupMessages(library(peekbankr))
suppressPackageStartupMessages(library(lme4))
suppressPackageStartupMessages(library(ggpmisc))
suppressPackageStartupMessages(library(ggrepel))
suppressPackageStartupMessages(library(ggthemes))

# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed, cache = TRUE, 
                      message=FALSE, warning=FALSE, error=FALSE)

load(file = here("explorations","data","d_trial.Rds"))
```

Our goal here is to model trial-level variation in accuracy for familiar word recognition across all the experiments in Peekbank. 

Let's move forward with ALL THE DATA (tm). Window will be something like 500 -- 4000  based on the above analysis (which is at best incomplete and at worst...).

```{r}
df <- d_trial |>
    filter(t_norm > 500, t_norm < 4000) |>
    group_by(dataset_name, dataset_id, administration_id, 
             age, stimulus_id, target_label, distractor_label) |>
    summarise(accuracy = mean(correct[t_norm > 0], na.rm=TRUE),
              prop_data = mean(!is.na(correct[t_norm > 0]))) 
df <- df[complete.cases(df),]
```

# Descriptives

How much data is there? 

```{r}
df %>%
  group_by(dataset_name) %>%
  count() %>%
  arrange(desc(n)) %>%
  DT::datatable()
```

```{r}
df %>%
  group_by(target_label) %>%
  count() %>%
  arrange(desc(n)) %>%
  DT::datatable()
```

Plot all trials by all participants.

```{r}
ggplot(df, aes(x = age/12, y = accuracy)) + 
  geom_point(alpha = .01) + 
  geom_smooth() + 
  geom_hline(lty = 2, yintercept = .5) + 
  ggthemes::theme_few()
```

Try breaking this down by word.

```{r}
hf_words = df |>
  group_by(target_label) |> 
  count() |>
  filter(n > 200)

ggplot(filter(df, target_label %in% hf_words$target_label, 
              age <= 36),
       aes(x = age/12, y = accuracy, col = target_label)) + 
  geom_point(alpha = .05) + 
  geom_smooth(se=FALSE) + 
  geom_hline(lty = 2, yintercept = .5)+ 
  ggthemes::theme_few()
```

We see lots of wiggliness here. Let's try to use a model to get this out. 

# First models

## Naive LMM

Trying to get in some random effect structure without blowing everything up. Scaling age is key.

```{r}
df$age_scaled <- scale(df$age)
mod <- lmer(accuracy ~ age_scaled + (1 | administration_id) + 
       (age_scaled | target_label) + 
       (1 | dataset_name), 
     data = df)

summary(mod)
```

Let's extract and plot the random effects. 

```{r}
t_ranefs <- ranef(mod)$target_label |>
  tibble() |>
  mutate(target_label = rownames(ranef(mod)$target_label)) |>
  mutate(target_label = fct_reorder(target_label, 
                                              `(Intercept)`)) |>
  pivot_longer(cols = -target_label, 
               names_to = "coefficient", 
               values_to = "value")
  

t_item_plot <- ggplot(filter(t_ranefs, target_label %in% hf_words$target_label),
       aes(x = target_label, y = value)) +
  facet_wrap(~coefficient) + 
  geom_point() + 
  coord_flip() + 
  ggthemes::theme_few()
t_item_plot
```

One question we might want to ask is, what's the best measure of word difficulty. I'm not sure! I would have guessed that baby and car would be easy, but not frog or cookie necessarily! I also wouldn't have said that apple would be hard.

If we do the predictions, though, we do see there are some very big study effects for the reflook studies, which have many kids and much older kids. This is tough variance to deal with. 

```{r}
newdata <- expand_grid(age_scaled = seq(min(df$age_scaled), max(df$age_scaled), .1), 
                       target_label = hf_words$target_label)
newdata$pred <- predict(mod, 
                        newdata = newdata, 
                        re.form = ~  (age_scaled | target_label), 
                        type = "response")
newdata$age <- (newdata$age_scaled * sd(df$age)) + mean(df$age)

ggplot(filter(df, target_label %in% hf_words$target_label),
       aes(x = age/12, y = accuracy, col = target_label)) + 
  geom_point(alpha = .1) + 
  geom_line(data = newdata, 
            aes(x = age/12, y = pred, col = target_label)) + 
  ggrepel::geom_text_repel(data = filter(newdata, 
                                         age == max(age)), 
                           aes(label = target_label, 
                               y = pred)) + 
  geom_hline(lty = 2, yintercept = .5) + 
  xlab("Age (years)") + 
  xlim(1, 6) + 
  ggthemes::theme_few()
```

## Distractor LMM

One possible reason for h4e 

```{r}
td_mod <- lmer(accuracy ~ age_scaled + 
                 (1 | administration_id) + 
                 (age_scaled | target_label) + 
                 (age_scaled | distractor_label) + 
                 (1 | dataset_name), 
     data = df)

summary(td_mod)
```

```{r}
newdata$pred <- predict(td_mod, 
                        newdata = newdata, 
                        re.form = ~ (age_scaled | target_label), 
                        type = "response")

ggplot(filter(df, target_label %in% hf_words$target_label),
       aes(x = age/12, y = accuracy, col = target_label)) + 
  geom_point(alpha = .1) + 
  geom_line(data = newdata, 
            aes(x = age/12, y = pred, col = target_label)) + 
  ggrepel::geom_text_repel(data = filter(newdata, 
                                         age == max(age)), 
                           aes(label = target_label, 
                               y = pred)) + 
  geom_hline(lty = 2, yintercept = .5) + 
  scale_color_discrete(guide = "none") + 
  xlab("Age (years)") + 
  xlim(1, 6) + 
  ggthemes::theme_few()
```

```{r}
td_ranefs <- ranef(td_mod)$target_label |>
  tibble() |>
  mutate(target_label = rownames(ranef(td_mod)$target_label)) |>
  mutate(target_label = fct_reorder(target_label, 
                                              `(Intercept)`)) |>
  pivot_longer(cols = -target_label, 
               names_to = "coefficient", 
               values_to = "value")


td_item_plot <- ggplot(filter(td_ranefs, target_label %in% hf_words$target_label),
       aes(x = target_label, y = value)) +
  facet_wrap(~coefficient) + 
  geom_point() + 
  coord_flip() + 
  ggthemes::theme_few()

cowplot::plot_grid(t_item_plot, td_item_plot)
```

Feels like this made a bit of a difference but perhaps not enough?

# Other curve types

Let's start by noting that there appears to be some functional form to these curves. Maybe capturing this form will help us summarize.  Descriptively, let's take a look at it word by word. 

## Exponentials

These asymptotic forms might be captured well by an exponential (following Kail 1990): 
$$
y \sim \alpha + \beta e^{-\gamma x}
$$

Where $x$ is age.

```{r}
# to keep logs from failing
df$accuracy_eps <- df$accuracy
df$accuracy_eps[df$accuracy == 0] <- .01

filter(df, target_label %in% hf_words$target_label) |>
ggplot(aes(x = age/12, y = accuracy_eps)) + 
  geom_point(alpha = .1) + 
  geom_smooth() +
  geom_smooth(col = "red", method = "lm", formula = y ~ I((exp(1)**(-x)))) +
  geom_hline(lty = 2, yintercept = .5) + 
  facet_wrap(~target_label)+ 
  ggthemes::theme_few()
```

One approach is to try and push the exponential into the regression, e.g. via `I((exp(1)**(-age_scaled)))` - but this actually leads to a linear slope and intercept adjustment on the exponent, which is not quite what we want. Instead, we actually want to fit the exponential. Notice that:

$$
log(y) \sim log(\beta e^{-\gamma x})\\
log(y) \sim log(\beta) - \gamma x
$$
This second formulation is just a linear equation in the log of y, so we can just fit that directly. Let's look at the log of accuracy to see what that looks like:

```{r}
ggplot(df, aes(x = age, y = log(accuracy))) +
         geom_point() + 
  geom_smooth(method = "lm")
```

The thing is, when you put this in the exponent, you get a positive slope of age. So we'll approximate with the negative exponential that's linearly weighted plus a linear age term.

```{r}
# df$age_scaled <- scale(df$age)
exp_mod <- lmer(accuracy ~ age_scaled + I((exp(1)**(-age_scaled))) + (1 | administration_id) + 
                  (age_scaled + I((exp(1)**(-age_scaled))) | target_label) +
                  (age_scaled + I((exp(1)**(-age_scaled))) | distractor_label) +
                  (1 | dataset_name), 
                data = df)

summary(exp_mod)
```



```{r}
newdata$pred <- predict(exp_mod, 
                        newdata = newdata, 
                        re.form = ~ (age_scaled + I((exp(1)**(-age_scaled))) | target_label), 
                        type = "response")

ggplot(filter(df, target_label %in% hf_words$target_label),
       aes(x = age/12, y = accuracy, col = target_label)) + 
  geom_point(alpha = .1) + 
  geom_line(data = newdata, 
            aes(x = age/12, y = pred, col = target_label)) + 
  ggrepel::geom_text_repel(data = filter(newdata, 
                                         age == max(age)), 
                           aes(label = target_label, 
                               y = pred)) + 
  scale_color_discrete(guide = "none") + 
  geom_hline(lty = 2, yintercept = .5) + 
  xlab("Age (years)") + 
  xlim(1, 6)+ 
  ggthemes::theme_few()
```

```{r}
anova(td_mod, exp_mod)
```

## Logits

One more try at finding a functional form, let's use a half-logit. That would be:

$$
y \sim .5 + .5\frac{1}{1+e^{\alpha + \beta x}}
$$


```{r}
# df$age_scaled <- scale(df$age)
hl_mod <- lmer(accuracy ~ I(.5 + .5 * (1 / (1 + exp(1)^(age_scaled)))) + (1 | administration_id) + 
       (I(.5 + .5 * (1 / (1 + exp(1)^(age_scaled))))| target_label) + 
         (I(.5 + .5 * (1 / (1 + exp(1)^(age_scaled))))| distractor_label) + 
       (1 | dataset_name), 
     data = df)

summary(hl_mod)
```

```{r}
anova(td_mod,hl_mod)
```

Somewhat surprisingly, the half logit approach works and fits better by quite a bit! 

```{r}
anova(exp_mod,hl_mod)
```

The exponentials and the half-logits are pretty similar. 


```{r}
newdata$pred <- predict(hl_mod, 
                        newdata = newdata, 
                        re.form = ~ (I(.5 + .5 * (1 / (1 + exp(1)^(age_scaled)))) | target_label), 
                        type = "response")

ggplot(filter(df, target_label %in% hf_words$target_label),
       aes(x = age/12, y = accuracy, col = target_label)) + 
  geom_point(alpha = .1) + 
  geom_line(data = newdata, 
            aes(x = age/12, y = pred, col = target_label)) + 
  ggrepel::geom_text_repel(data = filter(newdata, 
                                         age == max(age)), 
                           aes(label = target_label, 
                               y = pred), max.overlaps = 150) + 
  geom_hline(lty = 2, yintercept = .5) + 
  scale_color_discrete(guide = "none") + 
  xlab("Age (years)") + 
  xlim(1, 6)+ 
  ggthemes::theme_few()
```
Ok, so this is kind of entertaining, but it's not working perfectly in that the curves are all being shifted by an intercept, rather than the parameters of the logit being shifted... really we want to push the intercept inside the half-logit so that its slope gets moved around. Not sure how to do that right now. 

## Polynomials

Just for kicks, let's try second order orthogonal polynomials. This adds a parameter over the hl approach (not the exponentials), but maybe it'll get us some reasonable shapes. 

```{r}
# df$age_scaled <- scale(df$age)
poly_mod <- lmer(accuracy ~ poly(age_scaled,2) + (1 | administration_id) + 
                   (poly(age_scaled,2) | target_label) + 
                   (poly(age_scaled,2) | distractor_label) + 
                   (1 | dataset_name), 
                 data = df)

summary(poly_mod)
``` 
Model comparison to the exponentials.

```{r}
anova(exp_mod,poly_mod)

save(poly_mod, file = here("explorations","data","poly_mod.Rds"))

```

The polynomial model is somewhat better. Now visualize.

```{r}
newdata$pred <- predict(poly_mod, 
                        newdata = newdata, 
                        re.form = ~ (poly(age_scaled,2) | target_label), 
                        type = "response")

ggplot(filter(df, target_label %in% hf_words$target_label),
       aes(x = age/12, y = accuracy, col = target_label)) + 
  geom_point(alpha = .1) + 
  geom_line(data = newdata, 
            aes(x = age/12, y = pred, col = target_label)) + 
  ggrepel::geom_text_repel(data = filter(newdata, 
                                         age == max(age)), 
                           aes(label = target_label, 
                               y = pred), max.overlaps = 150) + 
  geom_hline(lty = 2, yintercept = .5) + 
  scale_color_discrete(guide = "none") + 
  xlab("Age (years)") + 
  xlim(1, 6) + 
  ggthemes::theme_few()
```
These curves look totally fine in shape and the polynomials are easy to interpret. 

# Average developmental trajectory

One question we might have is what the average developmental trajectory for accuracy is, across all words. Here's that graph. 

```{r}
newdata$pred <- predict(poly_mod, 
                        newdata = newdata, 
                        re.form = NA, 
                        type = "response")

ggplot(filter(df, target_label %in% hf_words$target_label),
       aes(x = age/12, y = accuracy, col = target_label)) + 
  geom_point(alpha = .1) + 
  geom_line(data = newdata, 
            aes(x = age/12, y = pred), col = "black", size = 1) + 
  ggrepel::geom_text_repel(data = filter(newdata, 
                                         age == max(age)), 
                           aes(label = target_label, 
                               y = pred)) + 
  geom_hline(lty = 2, yintercept = .5) + 
  scale_color_discrete(guide = "none") + 
  xlab("Age (years)") + 
  xlim(1, 5) + 
  ggthemes::theme_few()
```
Another question we might want to ask is, if we factor out lab and item-wise variation, what do predicted participant developmental trajectories look like? 

We can ask this by predicting from our fitted model, but removing the random effects. That should give us predicted values for each participant with the average study and item effects.

```{r}
df$pred <- predict(poly_mod, 
                   re.form = ~(1| administration_id), 
                   type = "response")

ms <- df %>%
  group_by(age, administration_id) %>%
  summarise(prediction = mean(pred), 
            accuracy = mean(accuracy)) %>%
  pivot_longer(cols = c(prediction, accuracy), names_to = "measure", values_to = "value")

ggplot(ms,
       aes(x = age/12, y = value)) + 
  geom_point(alpha = .05) + 
  # geom_line(aes(x = age/12, y = pred), col = "black", size = 1) + 
  geom_hline(lty = 2, yintercept = .5) + 
  geom_smooth(method = "lm", formula = y ~ poly(x,2)) + 
  scale_color_discrete(guide = "none") +
  facet_wrap(~measure) + 
  xlab("Age (years)") + 
  xlim(1, 5) + 
  ggthemes::theme_few() + 
  ggtitle("Mean accuracy vs. model-predicted subject variation")
```

