---
title: "Trial summary analysis"
author: "Mike"
date: "9/16/2021"
output: html_document
---

```{r setup, echo = FALSE}
library(here)
library(tidyverse)
library(peekbankr)
library(lme4)

# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(cache.extra = knitr::rand_seed)
```


This markdown documents a new way of thinking about modeling variation in LWL data. The idea is to try to:

1. extract a summary statistic for each trial
2. model these summaries with LMMs of various types

The trouble is, what's the right summary statistic? It might be that there's not just one! But let's assume there is one and we just need to sum it up right. 

So we'll start by trying to figure out what the best measure is. We're going to make decisions to maximize within-experiment reliability via ICCs.

We're focused on familiar words here. 


# Get data

```{r, eval=FALSE}
all_aoi_timepoints <- get_aoi_timepoints()
all_stimuli <- get_stimuli()
all_administrations <- get_administrations()
all_trial_types <- get_trial_types() 
all_trials <- get_trials() 
all_trials <- get_trials() 

aoi_data_joined <- all_aoi_timepoints |>
  right_join(all_administrations) |>
  right_join(all_trials) |>
  right_join(all_trial_types) |>
  mutate(stimulus_id = target_id) |>
  right_join(all_stimuli) |>
  select(dataset_name, administration_id, trial_id, dataset_id, stimulus_id, t_norm, age, aoi, english_stimulus_label, stimulus_novelty)

save(aoi_data_joined, file = here("data/aoi_data_joined.Rds"))
```

```{r}
load(file = here("data/aoi_data_joined.Rds"))
```

Take only familiar word data. 

```{r}
d_trial <- aoi_data_joined |>
  filter(dataset_name != "casillas_tseltal_2015") |>
  filter(age > 12, age <= 60, 
         stimulus_novelty == "familiar") |> 
  select(dataset_name, administration_id, trial_id, 
         dataset_id, stimulus_id, t_norm, age, aoi, english_stimulus_label) |>
  mutate(correct = ifelse(aoi == "target", 1, 
                          ifelse(aoi == "distractor", 0, NA)))
```

# Curve summaries

Now think about what the basic curve is and how to get out various measures. 

```{r}
ggplot(d_trial, aes(x = t_norm, y = correct)) + 
  geom_smooth()
```

Seems like we want something that captures 1) the accuracy and 2) the rise coming soon after zero (RT).

```{r}
d_summary <- d_trial |>
  group_by(dataset_name, dataset_id, administration_id, stimulus_id) |>
  summarise(accuracy = mean(correct[t_norm > 0], na.rm=TRUE),
            prop_data = mean(!is.na(correct[t_norm > 0])))

ggplot(d_summary, aes(x = prop_data, y = accuracy)) +
  geom_point(alpha = .05)
```
There's a lot of missing data and a lot of "zoners" (kids who look only at one side). Zoners are not just missing data kids.

```{r}
ggplot(filter(d_summary, prop_data > .75),
       aes(x = accuracy)) + 
  geom_histogram()
```

# Exclusions

There are two different decisions we could optimize:

1. exclude zoners?
2. exclude based on prop data

Let's try to figure those out. 

We're going to use ICCs, with McGraw & Wong (1996). It seems like we want two-way random effects, no interaction (subjects and items are meaningful). This is type "2A." We want average agreement across units.

One big decision is whether to look across stimulus items, rather than across kids. Across stimulus items returns *much* higher values. This is in part because we typically have more kids than items, and kids are sort of like "raters." 

```{r}
#devtools::install_github("jmgirard/agreement")
library(agreement)

get_icc <- function (x, column = "accuracy", object = "stimulus") {
  if (object == "stimulus") {
    iccs <- dim_icc(x, 
                    model = "2A", 
                    type = "agreement", 
                    unit = "average",
                    object = stimulus_id, 
                    rater = administration_id,
                    score = {{column}}, 
                    bootstrap = 0)
  } else {
    iccs <- dim_icc(x, 
                    model = "2A", 
                    type = "agreement", 
                    unit = "average",
                    object = administration_id, 
                    rater = stimulus_id,
                    score = {{column}}, 
                    bootstrap = 0)
  }
  
  return(iccs$Inter_ICC)
}

iccs <- d_summary |>
  group_by(dataset_name) |> 
  nest() |>
  mutate(icc_acc = unlist(map(data, get_icc))) |>
  select(-data) |>
  unnest(cols = c())

knitr::kable(iccs, digits = 2)
```

Let's look at one dataset. 

```{r}
sa <- d_summary |> 
  filter(dataset_name == "swingley_aslin_2002")

get_icc(sa, object = "stimulus")
get_icc(sa, object = "administration")

# ggplot(sa, aes(x = administration_id, y = accuracy, col = factor(stimulus_id))) +
  # geom_jitter(alpha = .2, width = .5) + 
  # geom_smooth(method = "lm", formula = y ~ 1, se = FALSE)
  
```


Now try to do this programmatically. 

```{r}

icc_sim <- function (zoners_included, exclude_less_than, object) 
{
  df <- d_summary |>
    filter(prop_data > exclude_less_than)
  
  # drop zoners
  if (zoners_included == FALSE) { 
    df <- filter(df, accuracy > 0, accuracy < 1) 
  }
  
  # compute ICCs
  df |> 
    group_by(dataset_name) |> 
    nest() |>
    mutate(icc = unlist(map(data, ~get_icc(., "accuracy", object)))) |>
    select(-data) |>
    unnest(cols = c()) 
}

excl_params <- expand_grid(zoners_included = c(FALSE, TRUE),
                           exclude_less_than = seq(.1, .9, .1), 
                           object = c("stimulus", "administration")) |>
  mutate(icc = pmap(list(zoners_included, exclude_less_than, object), icc_sim)) |>
  unnest(col = icc)
```

```{r}
ggplot(excl_params,
       aes(x = exclude_less_than, y = icc, col = zoners_included)) + 
  geom_jitter(width = .01, alpha = .5) + 
  geom_smooth(method = "lm") + 
  facet_wrap(~object)
```

# What's the measure? 


```{r}
icc_window_sim <- function (t_start = 0, t_end = 4000, object) 
{
  df <- d_trial |>
    filter(t_norm > t_start, t_norm < t_end) |>
    group_by(dataset_name, dataset_id, administration_id, stimulus_id) |>
    summarise(accuracy = mean(correct[t_norm > 0], na.rm=TRUE),
              prop_data = mean(!is.na(correct[t_norm > 0])))
  
  # compute ICCs
  df |> 
    group_by(dataset_name) |> 
    nest() |>
    mutate(icc = unlist(map(data, ~get_icc(., "accuracy", object)))) |>
    select(-data) |>
    unnest(cols = c()) 
}

window_params <- expand_grid(t_start = seq(0,1750,250),
                             t_end = seq(2000,4000,250),
                             object = c("stimulus", "administration")) |>
  mutate(icc = pmap(list(t_start, t_end, object), icc_window_sim)) |>
  unnest(col = icc)

```

```{r}
ggplot(window_params, aes(x = t_start, y = icc, col = as.factor(t_end))) + 
  geom_jitter() + 
  facet_wrap(~object) + 
  geom_smooth(aes(group = as.factor(t_end)), se = FALSE)
```

